{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Resnet_Cifar10.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nobrainkid/CNN/blob/main/Resnet_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enormous-warrant"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')"
      ],
      "id": "enormous-warrant",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radio-accident"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ####\n",
        "    # Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "id": "radio-accident",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "productive-analysis"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b', padding='same')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides=(1, 1), name=conv_name_base + '2c', padding='valid')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), name=conv_name_base + '1', padding='valid')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut) \n",
        "\n",
        "    # Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "id": "productive-analysis",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broad-bleeding"
      },
      "source": [
        "def ResNet(input_shape, classes):\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(32, (8, 8), strides = (2, 2), name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((4, 4), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "    X = MaxPooling2D((4, 4), strides=(2, 2), padding=\"same\")(X)\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [16, 16, 256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [16, 16, 256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [16, 16, 256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [16, 16, 256], stage=3, block='d')\n",
        "    X = identity_block(X, 3, [16, 16, 256], stage=3, block='e')\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(X)\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [8, 8, 512], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [8, 8, 512], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [8, 8, 512], stage=5, block='c')\n",
        "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet')\n",
        "\n",
        "    return model"
      ],
      "id": "broad-bleeding",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "green-dealer"
      },
      "source": [
        "def load_dataset():\n",
        "  (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "  # Normalize image vectors\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_train = X_train/255.\n",
        "  X_test = X_test/255.\n",
        "\n",
        "  Y_train = keras.utils.to_categorical(Y_train, 10)\n",
        "  Y_test = keras.utils.to_categorical(Y_test, 10)\n",
        "\n",
        "  # print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "  # print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "  # print (\"X_train shape: \" + str(X_train.shape))\n",
        "  # print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "  # print (\"X_test shape: \" + str(X_test.shape))\n",
        "  # print (\"Y_test shape: \" + str(Y_test.shape))\n",
        "\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "id": "green-dealer",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz4oJm8RHDcM",
        "outputId": "100254b7-b757-45fb-c643-b3ca7f43ad5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kf = KFold(n_splits = 5, random_state = 5, shuffle = True) \n",
        "X_train, Y_train, X_test, Y_test = load_dataset()\n",
        "start_epochs = 20\n",
        "i = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "  training_data = X_train[train_index]\n",
        "  training_labels = Y_train[train_index]\n",
        "  validation_data = X_train[val_index]\n",
        "  validation_labels = Y_train[val_index]\n",
        "  num_epochs = start_epochs * i\n",
        "\n",
        "  model = ResNet(input_shape = (32, 32, 3), classes = 10)\n",
        "  model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Generate extra data\n",
        "  datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                         height_shift_range=0.1,\n",
        "                         zoom_range=0.3,\n",
        "                         fill_mode='nearest',\n",
        "                         horizontal_flip = True)\n",
        "  \n",
        "  datagen.fit(training_data)\n",
        "\n",
        "\n",
        "  history = model.fit(datagen.flow(training_data, training_labels), epochs=num_epochs, validation_data=(validation_data, validation_labels))\n",
        "\n",
        "  model.save(str(num_epochs) + '_epochs_model')\n",
        "\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title(str(num_epochs) + ' epochs model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "  plt.savefig(str(num_epochs) + '_epochs_model.png')\n",
        "  i +=1"
      ],
      "id": "Cz4oJm8RHDcM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 146s 114ms/step - loss: 2.2422 - accuracy: 0.2248 - val_loss: 1.6872 - val_accuracy: 0.3846\n",
            "Epoch 2/20\n",
            " 838/1250 [===================>..........] - ETA: 46s - loss: 1.7899 - accuracy: 0.3561"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "disturbed-breed"
      },
      "source": [
        "# scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "id": "disturbed-breed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPPC4pb2tSqn"
      },
      "source": [
        "while True:\n",
        "  pass"
      ],
      "id": "FPPC4pb2tSqn",
      "execution_count": null,
      "outputs": []
    }
  ]
}